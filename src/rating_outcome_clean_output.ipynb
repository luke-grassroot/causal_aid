{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from importlib import reload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "\n",
    "import util.load as load_util\n",
    "import util.explore as explore_util\n",
    "import util.experiment as experiment\n",
    "\n",
    "from econml.dml import LinearDML, SparseLinearDML, NonParamDML\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_df = load_util.load_projects() # loads in aid data projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-alberta",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_out_crawl(specific_rating_col, outcome_col, feature_cols, sector_data_sets):\n",
    "    dml_results = []\n",
    "    for label in sector_data_sets:\n",
    "        dml_est, est_target, est_treatment, result_dict = experiment.perform_dml_on_df(\n",
    "            sector_data_sets[label], label, outcome_col, specific_rating_col, feature_cols)\n",
    "        dml_results.append(result_dict)\n",
    "        \n",
    "    return pd.DataFrame(dml_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_text(estimator, filename):\n",
    "    with open(f\"../results/rating_regressions/{filename}.txt\", \"w\") as file:\n",
    "        file.write(estimator.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result_df(result_df, filename):\n",
    "    result_df.to_csv(f\"../results/rating_regressions/{filename}.csv\", index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-disposal",
   "metadata": {},
   "source": [
    "### Education replication, ratings check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-laundry",
   "metadata": {},
   "source": [
    "1. Load in panel assembled by DG, and country code cross-matches\n",
    "2. For each country-year, calculate mean growth in education indicators at year + lag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-foundation",
   "metadata": {},
   "source": [
    "Education: Specification 2\n",
    "```\n",
    "regress  last_ner <- first_ner pc_commit_education [per capita commitment amount=\n",
    "        edu_share_gov_exp edu_pupil_teacher young_population\n",
    "        gdp_pc_ppp cash_surplus_deficit inflation trade_share_gdp\n",
    "        freedom_house i.period i.ncountrycode if countrytoinclude == 1, r\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_treatment_df = load_util.assemble_sector_ratings(project_df, 'Education').fillna(0) # loads in \n",
    "edu_df = pd.read_csv('../data/transformed_data/education_df.csv', index_col=0)\n",
    "    \n",
    "edu_df = experiment.add_project_and_aid_cols(edu_df, rated_too=False)\n",
    "print(edu_df.project_completed_year.value_counts())\n",
    "\n",
    "if 'edu_ner_lag5' not in edu_df:\n",
    "    print('Generating past net enrollment rates')\n",
    "    edu_df = explore_util.lag_variable_simple(edu_df, 'edu_ner', 5)\n",
    "\n",
    "if 'future_edu_ner' not in edu_df:\n",
    "    print('Generating future net enrollment rates')\n",
    "    edu_df = explore_util.lag_variable_simple(edu_df, 'edu_ner', -5)\n",
    "    edu_df = edu_df.rename(columns = { 'edu_ner_lag-5': 'future_edu_ner'})\n",
    "    \n",
    "edu_df['period'] = round((edu_df.year - 1900) / 5) - 10\n",
    "edu_df['prior_ner_growth'] = edu_df['edu_ner'] / edu_df['edu_ner_lag5']\n",
    "edu_df['edu_ner_pavg_5'] = explore_util.rolling_country_agg(edu_df, 'edu_ner', 5, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_target_col = 'edu_ner_pavg_5'\n",
    "\n",
    "treatment_cols = [\n",
    "    'mean_pc_last_5',\n",
    "    'mean_pc_last_5_ppd',\n",
    "    'mean_pc_last_5_wb'\n",
    "]\n",
    "\n",
    "rating_cols = ['education_max_proj_5yr', 'education_satisfactory_proj']\n",
    "\n",
    "edu_treatment_col = 'mean_pc_last_5'\n",
    "\n",
    "data_cols = [edu_target_col, edu_treatment_col] + rating_cols + [\n",
    "    'edu_share_gov_exp', 'edu_pupil_teacher', 'young_population', 'gdp_pc_ppp', \n",
    "    'cash_surplus_deficit', 'inflation', 'trade_share_gdp', 'freedom_house', 'prior_ner_growth'\n",
    "]\n",
    "\n",
    "initial_drop = ['prior_ner_growth', 'edu_share_gov_exp', 'prior_4year_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_est = experiment.evaluate_treatment(\n",
    "    edu_df, edu_target_col, edu_treatment_col, data_cols,\n",
    "    remove_feature_cols=initial_drop, \n",
    "    add_country_feffects=True, add_constant=False, \n",
    "    log_target=True, log_treatment=True, add_period_feffects=False)\n",
    "\n",
    "straight_results = experiment.extract_treatment_results(\n",
    "    'Replication', edu_est, edu_target_col, edu_treatment_col, data_cols, None\n",
    ")\n",
    "\n",
    "print(straight_results)\n",
    "print(edu_est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_args(arg_dict, default_args):\n",
    "    keys = [key for key in default_args if key not in arg_dict]\n",
    "    for key in keys:\n",
    "        arg_dict[key] = default_args[key]\n",
    "    return arg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_specifications(search_grid, default_args):\n",
    "    treatment_search_result = []\n",
    "    estimators = {}\n",
    "\n",
    "    for label, args in search_grid.items():\n",
    "        all_args = assemble_args(args, default_args)\n",
    "        est = experiment.evaluate_treatment(**all_args)\n",
    "        results = experiment.extract_treatment_results(\n",
    "            label, est, all_args['target_col'], all_args['treatment_col'], data_cols, {}\n",
    "        )\n",
    "        treatment_search_result.append(results)\n",
    "        estimators[label] = est\n",
    "\n",
    "    gsearch_results = pd.DataFrame(treatment_search_result)\n",
    "    return gsearch_results, estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_default_args = dict(df=edu_df, target_col=edu_target_col, treatment_col=edu_treatment_col,\n",
    "                   feature_cols=data_cols, add_country_feffects=True, add_constant=False, \n",
    "                    log_target=True, log_treatment=True)\n",
    "\n",
    "search_grid = {\n",
    "    'straight_replication': dict(\n",
    "        remove_feature_cols=['prior_ner_growth', 'edu_share_gov_exp', \n",
    "                             'w_avg_rating', 'satisfactory_proj', 'mean_pc_last_5_ppd', 'mean_pc_last_5_wb']\n",
    "    ),\n",
    "    'only_rated_aid_all_data': dict(\n",
    "        treatment_col='mean_pc_last_5_wb',\n",
    "        remove_feature_cols=['prior_ner_growth', 'edu_share_gov_exp', 'mean_pc_last_5', 'mean_pc_last_5_ppd']\n",
    "    ),\n",
    "    'only_rated_aid_narrow_data': dict(\n",
    "        treatment_col='mean_pc_last_5_ppd',\n",
    "        df=edu_df[edu_df.mean_pc_last_5_ppd > 0],\n",
    "        remove_feature_cols=['prior_ner_growth', 'edu_share_gov_exp', 'mean_pc_last_5', 'mean_pc_last_5_wb']\n",
    "    ),\n",
    "    'only_wb_data_narrow': dict(\n",
    "        treatment_col='mean_pc_last_5_wb',\n",
    "        df=edu_df[edu_df.mean_pc_last_5_wb > 0], remove_feature_cols=['mean_pc_last_5', 'mean_pc_last_5_ppd',\n",
    "                                                                        'edu_share_gov_exp', 'satisfactory_proj',\n",
    "                                                                     'education_satisfactory_proj', 'prior_ner_growth']\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_results, estimators = crawl_specifications(search_grid, edu_default_args)\n",
    "gsearch_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-nancy",
   "metadata": {},
   "source": [
    "*Now partialling out*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing partialling out first, as EconML results are proving volatile and highly counter-intuitive\n",
    "feature_cols = ['edu_share_gov_exp', 'edu_pupil_teacher', 'young_population', 'gdp_pc_ppp', \n",
    "             'cash_surplus_deficit', 'inflation', 'trade_share_gdp', 'freedom_house']\n",
    "\n",
    "edu_df['rolling_mean_edu_ner'] = explore_util.rolling_country_agg(edu_df, 'edu_ner', 5, 'mean')\n",
    "\n",
    "edu_df = explore_util.lag_variable_simple(edu_df, 'mean_pc_last_5_ppd', 1)\n",
    "edu_df = explore_util.lag_variable_simple(edu_df, 'w_avg_rating', 5)\n",
    "\n",
    "dlm_df = edu_df.copy()\n",
    "\n",
    "# perform some scaling\n",
    "cols_to_scale = ['rolling_mean_edu_ner', 'w_avg_rating_lag5', 'mean_pc_last_5_ppd_lag1', \"education_max_proj_5yr\"] + feature_cols\n",
    "for col in cols_to_scale:\n",
    "    dlm_df[col] = (dlm_df[col] - dlm_df[col].mean()) / dlm_df[col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_col = 'w_avg_rating_lag5'\n",
    "magnitude_col = 'mean_pc_last_5_ppd_lag1'\n",
    "target_col = 'rolling_mean_edu_ner'\n",
    "\n",
    "edu_data_sets = { \n",
    "    \"all_years\": dlm_df, \n",
    "    \"only_from_raters\": dlm_df[dlm_df[magnitude_col] > 0], \n",
    "    \"only_rated\": dlm_df[dlm_df[rating_col] > 0]\n",
    "}\n",
    "\n",
    "# only_rated_df = dlm_df[dlm_df[magnitude_col] > 0]\n",
    "\n",
    "max_proj_df = partial_out_crawl(\"education_max_proj_5yr\", target_col, cols_to_scale, edu_data_sets)\n",
    "last_proj_df = partial_out_crawl(\"w_avg_rating_lag5\", target_col, cols_to_scale, edu_data_sets)\n",
    "\n",
    "pout_edu_results = pd.concat((max_proj_df, last_proj_df)).round(2)\n",
    "pout_edu_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_edu_results = True\n",
    "\n",
    "if write_edu_results:\n",
    "    write_to_text(estimators['straight_replication'], \"edu_outcomes_no_ratings\")\n",
    "    write_to_text(estimators[\"only_rated_aid_all_data\"], \"edu_outcomes_only_rated_with_ratings\")\n",
    "    write_to_text(estimators[\"only_wb_data_narrow\"], \"edu_outcomes_only_wb_rated_narrow\")\n",
    "    write_result_df(gsearch_results, \"education_ratings_search\")\n",
    "    write_result_df(pout_edu_results, \"education_partialling_out\")\n",
    "#     gsearch_results.to_csv('../data/results/rating_regressions/education_ratings_search.csv', float_format='%.4f', index=False)\n",
    "#     pout_edu_results.to_csv('../data/results/rating_regressions/education_partialling_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-basketball",
   "metadata": {},
   "source": [
    "## Health"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-insurance",
   "metadata": {},
   "source": [
    "Process:\n",
    "\n",
    "1. Repeat outcome variable formation, using lagged construction\n",
    "2. Construct sectoral aid per capita using utilities\n",
    "3. Construct specification, using Diana's original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_treatment_df = load_util.assemble_sector_ratings(project_df, 'Health').fillna(0)\n",
    "health_df = pd.read_csv('../data/transformed_data/health_df.csv', index_col=0)\n",
    "health_df = experiment.add_project_and_aid_cols(health_df, sector='health', rated_too=True)\n",
    "\n",
    "treatment_cols = [col for col in health_treatment_df.columns if col not in [\"end_year\", \"country_code\"]]\n",
    "health_df[treatment_cols] = health_df[treatment_cols].fillna(0)\n",
    "print(\"Treatment counts: \", health_df.project_completed_year.value_counts())\n",
    "\n",
    "# take rolling five year averages of everything, following paper\n",
    "# note: not doing this for macro variables as justification does not make sense for those (measurement/volatility)\n",
    "measured_cols = ['mortality_under5', 'fertility', 'hiv_prevalence']\n",
    "\n",
    "for m_col in measured_cols:\n",
    "    health_df[f\"{m_col}_pavg\"] = explore_util.rolling_country_agg(health_df, m_col, 5, \"mean\")\n",
    "    health_df = explore_util.lag_variable_simple(health_df, f\"{m_col}_pavg\", 1)\n",
    "    \n",
    "macro_cols = [\"gdp_pc_ppp\", \"population\"]\n",
    "for m_col in macro_cols:\n",
    "    health_df = explore_util.lag_variable_simple(health_df, m_col, 1)\n",
    "\n",
    "health_df = explore_util.lag_variable_simple(health_df, \"mortality_under5_pavg\", 5)\n",
    "health_df[\"lag_log_mort\"] = np.log(health_df[\"mortality_under5_pavg_lag5\"])\n",
    "health_df['prior_mort_decline'] = health_df['mortality_under5_pavg'] / health_df['mortality_under5_pavg_lag5']\n",
    "health_df = explore_util.lag_variable_simple(health_df, \"w_avg_rating\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-parliament",
   "metadata": {},
   "source": [
    "* Specification 1:\n",
    "\n",
    "```qui regress mortality_under5 pc_commit_health lag_mortality_under5 ///\n",
    "            lag_gdp_pc_ppp lag_fertility lag_population ///\n",
    "            hiv_prevalence conflict i.period, r```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [\"mortality_under5_pavg\"]\n",
    "treatment_cols = [\"mean_pc_last_5_ppd\"]\n",
    "\n",
    "momentum_cols = [\"lag_log_mort\"]\n",
    "control_cols = [\n",
    "    \"hiv_prevalence_pavg_lag1\", \n",
    "    \"fertility_pavg_lag1\", \n",
    "    \"gdp_pc_ppp_lag1\", \n",
    "    \"population_lag1\", \n",
    "    \"conflict\"\n",
    "]\n",
    "\n",
    "rating_cols = [\n",
    "    'health_max_proj_5yr', \n",
    "    'w_avg_rating_lag5'\n",
    "]\n",
    "\n",
    "health_data_cols = [\"country\"] + target_cols + treatment_cols + momentum_cols + control_cols + rating_cols\n",
    "\n",
    "health_default_args = dict(df=health_df, target_col=\"mortality_under5_pavg\", treatment_col=treatment_cols[0],\n",
    "                           feature_cols=health_data_cols, add_constant=False, log_target=True, log_treatment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_est = experiment.evaluate_treatment(**health_default_args,\n",
    "                                           remove_feature_cols=[\"prior_mort_decline\"], \n",
    "                                           add_country_feffects=False)\n",
    "\n",
    "health_results = experiment.extract_treatment_results('Health Replication', health_est, 'mortality_under5_pavg', 'mean_pc_last_5_ppd', health_data_cols, None)\n",
    "print(health_est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-contemporary",
   "metadata": {},
   "source": [
    "* Specification 6\n",
    "\n",
    "```qui regress mortality_under5 pc_commit_health lag_mortality_under5 ///\n",
    "            lag_gdp_pc_ppp lag_fertility lag_population ///\n",
    "            lag_physicians_rate  lag_female_adult_literacy ///\n",
    "            lag_access_water lag_access_sanitation ///\n",
    "            hiv_prevalence conflict i.period i.nregionname, r```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_specifications = {\n",
    "    \"simple_replication\": dict(\n",
    "        remove_feature_cols=[\"prior_mort_decline\"], \n",
    "        add_country_feffects=False\n",
    "    ),\n",
    "    # add in controls for macro\n",
    "    \"replication_with_macro\": dict(\n",
    "        feature_cols=health_data_cols + ['inflation', 'cash_surplus_deficit', 'trade_share_gdp'],\n",
    "        treatment_col=\"mean_pc_last_5_ppd\",\n",
    "        remove_feature_cols=[\"mean_pc_last_5\"]\n",
    "    ),\n",
    "    \"replication_full_controls\": dict(\n",
    "        feature_cols=health_data_cols + ['access_water', 'access_sanitation', 'physicians_rate'],\n",
    "        treatment_col=\"mean_pc_last_5_ppd\",\n",
    "        remove_feature_cols=[\"mean_pc_last_5\"],\n",
    "        add_country_feffects=True, add_period_feffects=True\n",
    "    ),\n",
    "    # now just with positive rating\n",
    "    \"only_rated_data\": dict(\n",
    "        df=health_df[health_df.w_avg_rating > 0],\n",
    "        feature_cols=health_data_cols + ['access_water', 'access_sanitation', 'physicians_rate'],\n",
    "        treatment_col=\"mean_pc_last_5_ppd\",\n",
    "        remove_feature_cols=[\"mean_pc_last_5\"]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_gsearch, health_estimators = crawl_specifications(health_specifications, health_default_args)\n",
    "health_gsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(health_estimators[\"replication_full_controls\"].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(health_estimators[\"only_rated_data\"].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-origin",
   "metadata": {},
   "source": [
    "### Partialling out and EconML (on health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_df[\"log_mort\"] = np.log(health_df[\"mortality_under5_pavg\"])\n",
    "health_df[\"log_mean_pc_last_5\"] = np.log(health_df[\"mean_pc_last_5\"])\n",
    "health_df[\"log_proj_rating\"] = np.log(health_df[\"w_avg_rating\"].replace(0, np.nan)).fillna(0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_feature_cols = ['lag_log_mort', 'hiv_prevalence_pavg_lag1', 'fertility_pavg_lag1', 'gdp_pc_ppp_lag1', \n",
    "             'population_lag1']\n",
    "\n",
    "health_df = explore_util.lag_variable_simple(health_df, 'mean_pc_last_5_ppd', 1)\n",
    "health_df = explore_util.lag_variable_simple(health_df, 'w_avg_rating', 5)\n",
    "\n",
    "# do this manually first, as EconML results are proving volatile and highly counter-intuitive\n",
    "hdlm_df = health_df.copy()\n",
    "# do some scaling\n",
    "cols_to_scale = ['mortality_under5_pavg', 'w_avg_rating_lag5', 'health_max_proj_5yr', 'mean_pc_last_5_ppd_lag1'] + health_feature_cols\n",
    "for col in cols_to_scale:\n",
    "    hdlm_df[col] = (hdlm_df[col] - hdlm_df[col].mean()) / hdlm_df[col].std()\n",
    "\n",
    "rating_col = 'health_max_proj_5yr'\n",
    "magnitude_col = 'mean_pc_last_5_ppd_lag1'\n",
    "target_col = 'mortality_under5_pavg'\n",
    "\n",
    "health_data_sets = { \n",
    "    \"all_years\": hdlm_df, \n",
    "    \"only_from_raters\": hdlm_df[hdlm_df[magnitude_col] > 0], \n",
    "    \"only_rated\": hdlm_df[hdlm_df[rating_col] > 0]\n",
    "}\n",
    "\n",
    "max_proj_df = partial_out_crawl(\"health_max_proj_5yr\", target_col, cols_to_scale, health_data_sets)\n",
    "last_proj_df = partial_out_crawl(\"w_avg_rating_lag5\", target_col, cols_to_scale, health_data_sets)\n",
    "\n",
    "health_pout_results = pd.concat((max_proj_df, last_proj_df)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_pout_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_health_results = True\n",
    "\n",
    "if write_health_results:\n",
    "    write_to_text(health_estimators[\"simple_replication\"], \"health_outcomes_simple_replication\")\n",
    "    write_to_text(health_estimators['replication_full_controls'], \"health_outcomes_full_controls\")\n",
    "    write_to_text(health_estimators[\"only_rated_data\"], \"health_outcomes_only_wb_rated_narrow\")\n",
    "    health_gsearch.to_csv('../data/results/health_ratings_search.csv', float_format='%.4f')\n",
    "    health_pout_results.to_csv('../data/results/health_ratings_pout.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-symposium",
   "metadata": {},
   "source": [
    "## WASH replications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-personality",
   "metadata": {},
   "source": [
    "Access = a0 + a1 * Aid + a2 * Aid^2 + beta * controls + country FE + error term\n",
    "\n",
    "* Access (country, year) = access_water or access_sanitation  (each of them is separately used as the dependent variable, for Table 4 and Table 5, while the other is included as a lagged term in the controls). They also split urban and rural, but I think we can ignore this for now\n",
    "* Aid (country, year) = Aid targeted to the water and sanitation sector as a percentage of GDP. So Aid = 100 * commit_wash / (gdp_pc * population)\n",
    "* Controls (country, year): \n",
    "   - adult_literacy; log(gdp_pc), lagged(access_water or access_sanitation) and 3 others that are not exactly in the dataset but have reasonably close proxies:\n",
    "   - Government spending on health (% of GDP)  is not in the dataset, but a reasonably close one is health_share_gov_exp = Government health expenditure (% of general government expenditure)\n",
    "   - Age dependency ratio is not in the dataset, but a reasonably close one is young_population\n",
    "   - Government stability from ICRG is not in the dataset, but reasonably close ones are conflict and freedom_house\n",
    "* Other details:\n",
    "   - Period = 1990-2010\n",
    "   - Sample restricted to SSA countries only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "wash_df = health_df.copy()\n",
    "\n",
    "wash_df = experiment.add_project_and_aid_cols(wash_df, \"wash\")\n",
    "\n",
    "wash_df['wash_aid'] = wash_df['mean_pc_last_5'] * 100 / (wash_df['gdp_pc_ppp'])\n",
    "wash_df['wash_aid_sq'] = wash_df['wash_aid'] ** 2\n",
    "\n",
    "wash_df['log_gdp_pc'] = experiment.safe_log(wash_df, 'gdp_pc_ppp')\n",
    "wash_df = experiment.take_avg_and_lag(wash_df, \"health_share_gov_exp\")\n",
    "wash_df = experiment.take_avg_and_lag(wash_df, \"adult_literacy\")\n",
    "\n",
    "wash_df['access_water_pavg'] = explore_util.rolling_country_agg(wash_df, \"access_water\", 5, \"mean\")\n",
    "wash_df['access_san_pavg'] = explore_util.rolling_country_agg(wash_df, \"access_sanitation\", 5, \"mean\")\n",
    "\n",
    "wash_df = explore_util.lag_variable_simple(wash_df, 'access_water_pavg', 1)\n",
    "wash_df = explore_util.lag_variable_simple(wash_df, \"access_san_pavg\", 1)\n",
    "wash_df = explore_util.lag_variable_simple(wash_df, 'access_water_pavg', 5)\n",
    "wash_df = explore_util.lag_variable_simple(wash_df, \"access_san_pavg\", 5)\n",
    "\n",
    "wash_df['log_wash_aid_sq'] = experiment.safe_log(wash_df, 'wash_aid_sq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "wash_controls_constant = [\n",
    "    'adult_literacy_pavg', \n",
    "    'log_gdp_pc', \n",
    "    'health_share_gov_exp_pavg_lag1',\n",
    "    'young_population', 'conflict', 'freedom_house']\n",
    "\n",
    "wash_access_cols = ['access_water_pavg', 'access_san_pavg', 'access_water_pavg_lag5', 'access_san_pavg_lag5']\n",
    "wash_proj_cols = ['wash_satisfactory_proj', 'wash_max_proj_5yr']\n",
    "\n",
    "remove_for_water = [\"access_san_pavg\", \"access_water_pavg_lag5\"]\n",
    "remove_for_san = [\"access_water_pavg\", \"access_san_pavg_lag5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "wash_default_args = dict(\n",
    "    df=wash_df[wash_df.gdp_pc_ppp < 10000], treatment_col=\"wash_aid\",\n",
    "                feature_cols=wash_controls_constant + wash_access_cols + wash_proj_cols, # + ['log_wash_aid_sq'],\n",
    "                remove_feature_cols=remove_for_water,\n",
    "                log_target=True, log_treatment=True, add_constant=True, add_country_feffects=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_args = dict(target_col=\"access_water_pavg\", remove_feature_cols=remove_for_water)\n",
    "water_est = experiment.evaluate_treatment(**assemble_args(water_args, wash_default_args))\n",
    "# print(experiment.extract_treatment_results('Access to Water Estimate', water_est, 'access_water_pavg', 'wash_aid', wash_controls_constant, None))\n",
    "print(\"Doubling effect: \", 2 ** (water_est.params['wash_aid']) - 1)\n",
    "print(water_est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "san_args = dict(target_col=\"access_san_pavg\", remove_feature_cols=remove_for_san)\n",
    "san_est = experiment.evaluate_treatment(**assemble_args(san_args, wash_default_args))\n",
    "\n",
    "print(san_est.summary())\n",
    "print(\"Effect of doubling: \", 2 ** (san_est.params[\"wash_aid\"]) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_wash_results = False\n",
    "\n",
    "if write_wash_results:\n",
    "    write_to_text(water_est, \"water_initial_fe_linear\")\n",
    "    write_to_text(san_est, \"sanitation_initial_fe_linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-climb",
   "metadata": {},
   "source": [
    "### Partialling out and EconML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "wash_feature_cols = ['adult_literacy_pavg', 'log_gdp_pc', 'health_share_gov_exp_pavg_lag1',  \n",
    "             'young_population', 'conflict', 'freedom_house', 'access_water_pavg_lag5']\n",
    "\n",
    "wash_df = explore_util.lag_variable_simple(wash_df, 'mean_pc_last_5_ppd', 1)\n",
    "wash_df = explore_util.lag_variable_simple(wash_df, 'w_avg_rating', 5)\n",
    "\n",
    "# do this manually first, as EconML results are proving volatile and highly counter-intuitive\n",
    "wdlm_df = wash_df.copy()\n",
    "\n",
    "cols_to_scale = ['access_san_pavg', 'w_avg_rating_lag5', 'wash_max_proj_5yr', 'mean_pc_last_5_ppd_lag1'] + wash_feature_cols\n",
    "for col in cols_to_scale:\n",
    "    wdlm_df[col] = (wdlm_df[col] - wdlm_df[col].mean()) / wdlm_df[col].std()\n",
    "\n",
    "rating_col = 'wash_max_proj_5yr'\n",
    "magnitude_col = 'mean_pc_last_5_ppd_lag1'\n",
    "target_col = 'access_san_pavg'\n",
    "\n",
    "wash_data_sets = { \n",
    "    \"all_years\": wdlm_df, \n",
    "    \"only_from_raters\": wdlm_df[wdlm_df[magnitude_col] > 0], \n",
    "    \"only_rated\": wdlm_df[wdlm_df[rating_col] > 0]\n",
    "}\n",
    "\n",
    "wash_max_proj_df = partial_out_crawl(\"wash_max_proj_5yr\", target_col, cols_to_scale, wash_data_sets)\n",
    "wash_last_proj_df = partial_out_crawl(\"w_avg_rating_lag5\", target_col, cols_to_scale, wash_data_sets)\n",
    "\n",
    "wash_pout_results = pd.concat((wash_max_proj_df, wash_last_proj_df)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "wash_pout_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-parking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "causal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
