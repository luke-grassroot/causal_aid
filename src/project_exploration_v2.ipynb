{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "objective-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "import util.explore as explore_util\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from econml.dml import NonParamDML\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "timely-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-stack",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Code for sector\n",
    "2. Load in MDG panel\n",
    "3. Construct non-lag project - MDG DF for sector, with vars as in specifications\n",
    "4. Extract further project features: size relative to GDP, ratings, basic features of PDO and descriptions, etc.\n",
    "5. Do some crawls over lag periods, features and feature combinations\n",
    "6. Get ready for some graph work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-novelty",
   "metadata": {},
   "source": [
    "Note: for completion stuff, get hold of:\n",
    "\n",
    "Implementation Completion and Results Report\n",
    "Implementation Completion Report Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-attack",
   "metadata": {},
   "source": [
    "## Load in all projects from WB project panel, and merge with MDG panel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_projects = pd.read_csv('../data/clean_wb_proj_all.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "reassemble_proj_country_df = False\n",
    "\n",
    "df = pd.read_json(\"../data/aggregated_proj.json\", orient=\"index\")\n",
    "country_panel = pd.read_csv('../data/countrypanel.csv')\n",
    "\n",
    "if reassemble_proj_country_df:\n",
    "    df['boardapprovaldate'] = pd.to_datetime(df['boardapprovaldate'])\n",
    "    df['closingdate'] = pd.to_datetime(df['closingdate'])\n",
    "    df['closingyear'] = df.closingdate.dt.year\n",
    "\n",
    "\n",
    "    new_country_df = pd.read_csv('../data/tmp/project_countries.csv')\n",
    "\n",
    "    ndf = df.merge(new_country_df[['project_country', 'panel_country']], \n",
    "                   left_on='countryname', right_on='project_country', how='left')\n",
    "\n",
    "    ndf = ndf.drop(columns=['countryname'])\n",
    "    ndf = ndf[ndf.panel_country.notna()]\n",
    "    \n",
    "    save_transformed_df = False\n",
    "    if save_transformed_df:\n",
    "        ndf.to_csv('../data/transformed_data/projects_with_ccodes.csv')\n",
    "\n",
    "else:\n",
    "    ndf = pd.read_csv('../data/transformed_data/projects_with_ccodes.csv', index_col=0, low_memory=False)\n",
    "    ndf['boardapprovaldate'] = pd.to_datetime(ndf['boardapprovaldate'])\n",
    "    ndf['closingdate'] = pd.to_datetime(ndf['closingdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipf_data = pd.read_csv('../data/prior_proj_paper/ipf_paper_data.csv')\n",
    "print(ndf.id.isin(ipf_data.projid).sum())\n",
    "\n",
    "ipf_feature_cols = [\n",
    "    'origcommamt',\n",
    "    'cpia_approval',\n",
    "    'region',\n",
    "    'gp',\n",
    "    'fundingsource',\n",
    "    'fcsatappfy',\n",
    "    'uppermiddle_income_appfy',\n",
    "    'origprojlength',\n",
    "    'prepttl_exp',\n",
    "    'prepttl_quality_va'    \n",
    "]\n",
    "\n",
    "ndf = ndf.merge(ipf_data[['projid'] + ipf_feature_cols], left_on='id', right_on='projid', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-switch",
   "metadata": {},
   "source": [
    "What is:\n",
    "* mjthemecode\n",
    "\n",
    "Also, these have XML / extractable information:\n",
    "* indicatormappingdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/transformed_data/title_pdo_embeds_reduced.pkl\", \"rb\") as fin:\n",
    "    embeddings = pickle.load(fin)\n",
    "\n",
    "em_ext = dict(\n",
    "    project_id=embeddings[\"project_ids\"],\n",
    "    embed_x=embeddings[\"tsne\"][:, 0],\n",
    "    embed_y=embeddings[\"tsne\"][:, 1]\n",
    ")\n",
    "embed_df = pd.DataFrame(em_ext)\n",
    "\n",
    "ndf = ndf.merge(embed_df, left_on=\"id\", right_on=\"project_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dli_df = pd.read_csv('../data/transformed_data/clean_dli_pdo_tsne_sector.csv')\n",
    "dli_df = dli_df.rename(columns={ 'tsne_x': 'dli_x', 'tsne_y': 'dli_y' })\n",
    "\n",
    "ndf = ndf.merge(dli_df[['id', 'dli_x', 'dli_y']], how='left')\n",
    "\n",
    "sector_df = pd.read_csv('../data/prior_proj_paper/WB_project_sectors.csv').rename(columns={ 'proj_id': 'id' })\n",
    "main_sector_df = sector_df[sector_df.flag_main_sector == 1]\n",
    "main_sector_df.head()\n",
    "\n",
    "ndf = ndf.merge(main_sector_df[['id', 'sector_code', 'sector_percentage', 'parent_sector_name']], how='left')\n",
    "\n",
    "ndf['dli_x'] = ndf['dli_x'].fillna(0)\n",
    "ndf['dli_y'] = ndf['dli_y'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-lesbian",
   "metadata": {},
   "source": [
    "### Primary data complete, now extract the features we will work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_features = [\n",
    "     'id', \n",
    "     'regionname', \n",
    "     'project_name', \n",
    "     'pdo', \n",
    "     'boardapprovaldate', \n",
    "     'closingdate', \n",
    "     'closingyear', \n",
    "     'project_country', \n",
    "     'panel_country',\n",
    "]\n",
    "\n",
    "loan_features = [\n",
    "    'projectfinancialtype',\n",
    "    'lendinginstr',\n",
    "    'sector_percentage' # = percentage in primary sector\n",
    "] + ipf_feature_cols\n",
    "\n",
    "# not using combined practice code as limited in reach )recent projects) and seems fairly concentrated\n",
    "sector_features = [\n",
    "    'sector1', 'sector2', 'sector3', 'sector4', 'sector5', 'theme1', 'theme2'\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'impagency',\n",
    "    'cons_serv_reqd_ind',\n",
    "    'supplementprojectflg',\n",
    "    'prodlinetext',\n",
    "    'parent_sector_name'\n",
    "]\n",
    "\n",
    "embed_features = [\n",
    "    'embed_x',\n",
    "    'embed_y',\n",
    "    'dli_x',\n",
    "    'dli_y'\n",
    "]\n",
    "\n",
    "wdf = ndf[basic_features + loan_features + sector_features + cat_features + embed_features].fillna(0)\n",
    "wdf['all_sectors_theme_words'] = wdf[sector_features].apply(lambda row: ' '.join(row.values.astype(str)), axis=1).str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-toronto",
   "metadata": {},
   "source": [
    "## Sector coding\n",
    "\n",
    "\n",
    "* Code projects as health if one of their sectors/themes includes health (and same for education). This seems to pick up more than using the main sector or other sector columns\n",
    "* For WASH: use water, sanitation, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf['is_health_project'] = wdf.all_sectors_theme_words.str.contains('health')\n",
    "wdf['is_education_project'] = wdf.all_sectors_theme_words.str.contains('edu')\n",
    "\n",
    "print(\"Health: \" , wdf.is_health_project.value_counts())\n",
    "print(\"Education: \", wdf.is_education_project.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wdf.merge(country_panel.drop(columns=['regionname']), \n",
    "                                    left_on=['panel_country', 'closingyear'], right_on=['countryname', 'year'])\n",
    "\n",
    "data = data.drop(columns=['countryname', 'year'])\n",
    "data = data[data.closingyear.notna()]\n",
    "data['pdo_length'] = data['pdo'].str.len().fillna(0)\n",
    "\n",
    "data = data.rename(columns = { 'project_country': 'country', 'closingyear': 'year' })\n",
    "data = explore_util.lag_variable_simple(data, 'gdp_pc_ppp', -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in data.columns if 'mortality' in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-eating",
   "metadata": {},
   "source": [
    "We do a negative lag to obtain the value in the future (here just doing gdp pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_feature_imp(category_name, feature_imp, exp_features):\n",
    "    return sum([feature_imp[col] for col in exp_features if col.startswith(category_name)])\n",
    "\n",
    "def extract_feature_imp(est, orig_features, exp_features):\n",
    "    feature_imp = { col: est.feature_importances_[i] for i, col in enumerate(exp_features) }\n",
    "    summed_feature_imp = { col: sum_feature_imp(col, feature_imp, exp_features) for col in orig_features }\n",
    "    return feature_imp, summed_feature_imp\n",
    "\n",
    "def fit_score_model(X, y, est, classification=False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y if classification else None)\n",
    "    \n",
    "    est.fit(X_train, y_train)\n",
    "    scores = { 'default_score': est.score(X_test, y_test) }\n",
    "    if classification:\n",
    "        true_pred = est.predict_proba(X_test)[:, 1]\n",
    "        scores['fscore_etc'] = precision_recall_fscore_support(y_test, est.predict(X_test), average=\"binary\")\n",
    "        scores['roc_auc'] = roc_auc_score(y_test, true_pred)\n",
    "        scores['roc_curve'] = roc_curve(y_test, true_pred)\n",
    "    else:\n",
    "        scores['mape'] = mean_absolute_percentage_error(y_test, est.predict(X_test))\n",
    "    test_data = { \"X_test\": X_test, \"y_test\": y_test }\n",
    "    return est, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial_imp_features = [\n",
    "    'cons_serv_reqd_ind', \n",
    "    'impagency',\n",
    "    'prodlinetext',\n",
    "    'supplementprojectflg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_target = 'mortality_under5_lag-5'\n",
    "\n",
    "health_to_lag = {\n",
    "    'mortality_under5': -5,\n",
    "    'hiv_prevalence': -5,\n",
    "    'conflict': -5\n",
    "}\n",
    "\n",
    "health_observed_X_cols = [\n",
    "#     'mortality_under5', # = lag_mortality_under5 (since now evaluating at closure year)\n",
    "    'gdp_pc_ppp',\n",
    "    'fertility',\n",
    "    'population',\n",
    "    'physicians_rate',\n",
    "    'female_adult_literacy',\n",
    "    'access_water',\n",
    "    'access_sanitation',\n",
    "    'hiv_prevalence_lag-5'\n",
    "]\n",
    "\n",
    "probe_feature_cols = loan_features + cat_features + ['pdo_length'] + embed_features\n",
    "probe_feature_cols = [col for col in probe_feature_cols if col not in trivial_imp_features]\n",
    "\n",
    "health_results = end_to_end_project_eval(\n",
    "    data, \"health\", \"mortality_under5_lag-5\", health_to_lag,\n",
    "    observed_X_cols=health_observed_X_cols, \n",
    "    loan_feature_cols=probe_feature_cols,\n",
    "    inverted_outcome=True\n",
    ")\n",
    "\n",
    "print(\"Results for health check: \", health_results[\"classifier_scores\"])\n",
    "print({ key: round(value, 3) for key, value in health_results[\"summed_importances\"].items() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fpr, clf_tpr, _ = health_results[\"classifier_scores\"][\"roc_curve\"]\n",
    "plt.plot(clf_fpr, clf_tpr, marker='.', label='Model')\n",
    "# len(health_results[\"classifier_scores\"][\"roc_curve\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the education projects only\n",
    "# extract further project features\n",
    "# run through catboost, econml and the like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_to_end_project_eval(all_data, sector_key_word, target_col, variables_to_lag, observed_X_cols, loan_feature_cols, \n",
    "                            regressor=RandomForestRegressor, classifier=RandomForestClassifier, inverted_outcome=False):\n",
    "    sector_data = all_data.copy()\n",
    "    \n",
    "    for var in variables_to_lag:\n",
    "        sector_data = explore_util.lag_variable_simple(sector_data, var, variables_to_lag[var])\n",
    "    \n",
    "    sector_data['is_sector_project'] = sector_data.all_sectors_theme_words.str.contains(sector_key_word)\n",
    "    sector_data = sector_data[sector_data.is_sector_project]\n",
    "    print(\"Sector projects data: \", len(sector_data), \" versus all projects: \", len(all_data))\n",
    "    \n",
    "    sdata = sector_data[['id'] + observed_X_cols + [target_col]]\n",
    "    sdata = sdata.dropna()\n",
    "    print(\"Clean observations: \", len(sdata))\n",
    "\n",
    "    # print(\"Pre scaling: \", sdata[observed_X_cols[:2]].describe())\n",
    "    observation_scaler = StandardScaler()\n",
    "    sdata[observed_X_cols] = observation_scaler.fit_transform(sdata[observed_X_cols])\n",
    "    # print(\"Shape of endog: \", sdata[target_col].shape, \" and exog: \", sm.add_constant(sdata[observed_X_cols]).shape)\n",
    "    res_est = sm.OLS(endog=sdata[target_col], exog=sm.add_constant(sdata[observed_X_cols])).fit()\n",
    "    print(\"Naive R squared of partialling out phase: \", res_est.rsquared, \" and f_p: \", res_est.f_pvalue)\n",
    "    # print(\"Post scaling: \", sdata[observed_X_cols[:2]].describe())\n",
    "    \n",
    "    target_resid = f\"residual_target\"\n",
    "    sdata[target_resid] = res_est.resid\n",
    "    \n",
    "    forest_data = sdata[['id', target_resid]].merge(all_data[['id'] + loan_feature_cols], how='inner')\n",
    "#     print(forest_data.isna().sum())\n",
    "    pre_scale_target_desc = forest_data[target_resid].describe()\n",
    "    print(\"Descriptive stats for target: \", pre_scale_target_desc)\n",
    "    \n",
    "    numeric_cols = forest_data.select_dtypes(include=np.number).columns.tolist()\n",
    "    treatment_scaler = StandardScaler()\n",
    "    forest_data[numeric_cols] = treatment_scaler.fit_transform(forest_data[numeric_cols])\n",
    "\n",
    "    categorical_cols = [col for col in loan_feature_cols if col not in numeric_cols]\n",
    "    forest_data = pd.get_dummies(forest_data, columns=categorical_cols)\n",
    "\n",
    "    forest_data = forest_data.dropna()\n",
    "    print(\"Clean within project characteristics: \", len(forest_data))\n",
    "    \n",
    "    pos_std_dev_threshold = 0.1\n",
    "    forest_data[f'{target_resid}_above_threshold'] = (\n",
    "        forest_data[target_resid] > pos_std_dev_threshold if not inverted_outcome else \n",
    "            forest_data[target_resid] < pos_std_dev_threshold\n",
    "    )\n",
    "    print(\"Projects with residual above mean: \", len(forest_data[forest_data[target_resid] > 0]))\n",
    "    print(\"Projects with positive residual above threshold: \", len(forest_data[forest_data[target_resid] > pos_std_dev_threshold]))\n",
    "    \n",
    "    nreg = regressor()\n",
    "    nest = classifier()\n",
    "    \n",
    "    X = forest_data.drop(columns=['id', target_resid, f'{target_resid}_above_threshold'])\n",
    "    \n",
    "    y_reg = forest_data[target_resid]\n",
    "    y_class = forest_data[f'{target_resid}_above_threshold']\n",
    "    \n",
    "    reg_fit, reg_scores = fit_score_model(X, y_reg, nreg)\n",
    "    bin_est, bin_scores = fit_score_model(X, y_class, nest, classification=True)\n",
    "    \n",
    "    all_col_imp, summed_imp = extract_feature_imp(bin_est, loan_feature_cols, X.columns)\n",
    "    summed_imp = { feature: score for feature, score in sorted(summed_imp.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    return {\n",
    "        \"partial_out_model\": res_est,\n",
    "        \"residual_regressor\": reg_fit,\n",
    "        \"residual_classifier\": bin_est,\n",
    "        \"regression_scores\": reg_scores,\n",
    "        \"classifier_scores\": bin_scores,\n",
    "        \"pre_scale_target_stats\": pre_scale_target_desc,\n",
    "        \"summed_importances\": summed_imp,\n",
    "        \"all_importances\": all_col_imp,\n",
    "        \"residual_df\": forest_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in data.columns if \"edu\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_target = 'edu_aner_lag-5'\n",
    "\n",
    "edu_to_lag = {\n",
    "    'edu_aner': -5,\n",
    "    'edu_share_gov_exp': -5,\n",
    "    'edu_pupil_teacher': -5,\n",
    "    'young_population': -5,\n",
    "    'cash_surplus_deficit': -5, \n",
    "    'inflation': -5,\n",
    "    'trade_share_gdp': -5,\n",
    "    'freedom_house': -5\n",
    "}\n",
    "\n",
    "edu_observed_X_cols = [f\"{obs_col}_lag-5\" for obs_col in edu_to_lag.keys() if obs_col != \"edu_aner\"]\n",
    "\n",
    "edu_results = end_to_end_project_eval(\n",
    "    data, \"edu\", \"edu_aner_lag-5\", edu_to_lag,\n",
    "    observed_X_cols=edu_observed_X_cols, \n",
    "    loan_feature_cols=probe_feature_cols,\n",
    "    inverted_outcome=True\n",
    ")\n",
    "\n",
    "print(\"Results for education check: \", edu_results[\"classifier_scores\"])\n",
    "print({ key: round(value, 3) for key, value in edu_results[\"summed_importances\"].items() })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-argentina",
   "metadata": {},
   "source": [
    "```qui regress mortality_under5 pc_commit_health lag_mortality_under5 ///\n",
    "            lag_gdp_pc_ppp lag_fertility lag_population ///\n",
    "            lag_physicians_rate  lag_female_adult_literacy ///\n",
    "            lag_access_water lag_access_sanitation ///\n",
    "            hiv_prevalence conflict i.period i.nregionname, r```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_df = pd.concat((health_results[\"residual_df\"], edu_results[\"residual_df\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in consolidated_df.columns if \"residual\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_df = consolidated_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = consolidated_df.drop(columns=['id', \"residual_target\", f'residual_target_above_threshold'])\n",
    "\n",
    "y_reg = consolidated_df[\"residual_target\"]\n",
    "y_class = consolidated_df['residual_target_above_threshold']\n",
    "\n",
    "reg_fit, reg_scores = fit_score_model(X, y_reg, RandomForestRegressor())\n",
    "bin_est, bin_scores = fit_score_model(X, y_class, RandomForestClassifier(), classification=True)\n",
    "\n",
    "all_col_imp, summed_imp = extract_feature_imp(bin_est, probe_feature_cols, X.columns)\n",
    "summed_imp = { feature: score for feature, score in sorted(summed_imp.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "bin_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-wound",
   "metadata": {},
   "source": [
    "## Build better models / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try: SVC, Lasso, and a few others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_est, bin_scores = fit_score_model(X, y_class, SVC(probability=True), classification=True)\n",
    "\n",
    "# all_col_imp, summed_imp = extract_feature_imp(bin_est, probe_feature_cols, X.columns)\n",
    "# summed_imp = { feature: score for feature, score in sorted(summed_imp.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "bin_scores[\"roc_auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_est, bin_scores = fit_score_model(X, y_class, XGBClassifier(), classification=True)\n",
    "\n",
    "bin_scores[\"roc_auc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-bangkok",
   "metadata": {},
   "source": [
    "## Extract SHAP and other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-resident",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "causal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
