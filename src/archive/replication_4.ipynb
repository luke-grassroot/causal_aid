{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from dowhy import CausalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"mode.chained_assignment\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.load as load_util\n",
    "import util.explore as explore_util\n",
    "import util.experiment as experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_df = load_util.load_projects()\n",
    "edu_treatment_df = load_util.assemble_sector_ratings(project_df, 'Education').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_treatment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-genetics",
   "metadata": {},
   "source": [
    "## First approach: binary treatment, replicating papers on causal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in panel assembled by DG, and country code cross-matches\n",
    "# for each country-year, calculate mean growth in education indicators at year + lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_df, panel_source = experiment.assemble_replication_panel('education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = panel_df.merge(edu_treatment_df, how='left', left_on=['year', 'country'], right_on=['end_year', 'country_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/transformed_data/education_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_cols = [col for col in edu_treatment_df.columns if col not in [\"end_year\", \"country_code\"]]\n",
    "df[treatment_cols] = df[treatment_cols].fillna(0)\n",
    "df.project_completed_year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_lagged(col, country, year, lag_years, take_agg=False, agg_function=None):\n",
    "    if take_agg:\n",
    "        start_year = year if lag_years > 0 else year + lag_years\n",
    "        end_year = year + lag_years if lag_years > 0 else year\n",
    "        years = df[(df.country == country) & (df.year >= start_year) & (df.year < end_year)]\n",
    "        if len(years) == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return agg_function(years[col])\n",
    "    else:\n",
    "        future = df[(df.country == country) & (df.year == year + lag_years)]\n",
    "        if len(future) == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return future.iloc[0].to_dict()[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain_lagged('pc_commit_education', 'GNQ', 2005, -5)\n",
    "# df[(df.country == 'GNQ') & (df.year > 2000)][['year', 'edu_ner', 'pc_commit_education', 'mean_pc_last_5', 'lagged_edu_ner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'mean_pc_last_5' not in df:\n",
    "    print('Generating mean per capita commitments over prior years')\n",
    "    df['mean_pc_last_5'] = df.apply(lambda row: obtain_lagged('pc_commit_education', row['country'], row['year'], -5, take_mean=True), axis=1)\n",
    "\n",
    "if 'lagged_edu_ner' not in df:\n",
    "    print('Generating past net enrollment rates')\n",
    "    df['lagged_edu_ner'] = df.apply(lambda row: obtain_lagged('edu_ner', row['country'], row['year'], -5), axis=1)\n",
    "    \n",
    "if 'future_edu_ner' not in df:\n",
    "    print('Generating future net enrollment rates')\n",
    "    df['future_edu_ner'] = df.apply(lambda row: obtain_lagged('edu_ner', row['country'], row['year'], 5), axis=1)\n",
    "    \n",
    "if 'satisfactory_proj' not in df:\n",
    "    print('Marking whether a satisfactory project concluded in that year')\n",
    "    df['satisfactory_proj'] = (df['max_rating'] > 3).astype(int)\n",
    "    \n",
    "if 'max_proj_rating_5' not in df:\n",
    "    print('Taking maximum of weighted rating of concluded projects in prior period')\n",
    "    df['max_proj_rating_5'] = df.apply(lambda row: obtain_lagged('w_avg_rating', row['country'], row['year'], -5, take_agg=True, agg_function=np.max), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = False\n",
    "\n",
    "if store_df:\n",
    "    df.to_csv('../data/transformed_data/education_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max_proj_rating_5.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_non_data = ['year', 'countrycode', 'regionname', 'fcv_ind', 'lendingtype', 'incomelevel']\n",
    "non_data_cols = ['year', 'country', 'ppd_countrycode', 'wdi_countryname', 'project_completed_year'] + panel_non_data\n",
    "data_cols = [col for col in df.columns if col not in non_data_cols]\n",
    "ddf_data_cols = [col for col in panel_source.columns if col not in panel_non_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_culps = lambda culpc: (\n",
    "    { key: value for key, value in sorted(culprit_counts.items(), key=lambda item: item[1], reverse=True) if value > 0 }\n",
    ") \n",
    "culprit_counts, null_df = experiment.extract_culprit_counts(df, data_cols)\n",
    "print(non_zero_culps(culprit_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_culprits, ddf_nulls = experiment.extract_culprit_counts(panel_source, ddf_data_cols)\n",
    "print(non_zero_culps(ddf_culprits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-probe",
   "metadata": {},
   "source": [
    "*Note*: There is no surplus deficit in the standard WDI, so using net borrowing in year (is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding categorical variables for country, for replication purposes, although means dimensionality explosion (for unclear gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-petroleum",
   "metadata": {},
   "source": [
    "Education: Specification 2\n",
    "```\n",
    "regress  last_ner <- first_ner pc_commit_education [per capita commitment amount=\n",
    "        edu_share_gov_exp edu_pupil_teacher young_population\n",
    "        gdp_pc_ppp cash_surplus_deficit inflation trade_share_gdp\n",
    "        freedom_house i.period i.ncountrycode if countrytoinclude == 1, r\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={ 'education_lag_-4_growth': 'prior_4year_growth' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_treatment(df, target_col, treatment_col, feature_cols,\n",
    "                       log_target=False, log_treatment=False, remove_feature_cols=[], # this last is convenience \n",
    "                       add_country_feffects=True, add_constant=True):\n",
    "    data = df.copy() # else logs overwrite\n",
    "    if treatment_col not in feature_cols:\n",
    "        feature_cols += [treatment_col]\n",
    "    ols_cols = [col for col in feature_cols if col not in remove_feature_cols]\n",
    "    if log_target:\n",
    "        data[target_col] = np.log(data[target_col].replace(0, np.nan)).fillna(0)\n",
    "    if log_treatment:\n",
    "        data[treatment_col] = np.log(data[treatment_col].replace(0, np.nan)).fillna(0)\n",
    "    \n",
    "    est = experiment.plain_vanilla_ols(data, target_col, ols_cols, \n",
    "                                       add_country_feffects=add_country_feffects, \n",
    "                                       add_constant=add_constant)\n",
    "    \n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prior_ner_growth'] = df['edu_ner'] / df['lagged_edu_ner']\n",
    "df[(df.country == 'GNQ') & (df.year > 2000)][['year', 'country', 'edu_ner', 'lagged_edu_ner', 'prior_ner_growth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = ['country', 'satisfactory_proj', 'w_avg_rating', 'prior_ner_growth', 'edu_ner',\n",
    "                        'mean_pc_last_5', 'edu_pupil_teacher', \n",
    "                        'young_population', 'gdp_pc_ppp', 'cash_surplus_deficit', 'inflation', 'trade_share_gdp',\n",
    "                        'freedom_house', 'prior_4year_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first go for the paper\n",
    "r_est = evaluate_treatment(df, 'edu_ner', 'mean_pc_last_5', data_cols,\n",
    "                          remove_feature_cols=['prior_ner_growth', 'w_avg_rating', 'satisfactory_proj', 'prior_4year_growth'],\n",
    "                          add_country_feffects=True, add_constant=False, log_target=True, log_treatment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_treatment_results(label, est, target_col, treatment_col, feature_cols, est_kwards, sig_level=0.05):\n",
    "    sig_params = [param for param in est.params.keys() if est.pvalues[param] < sig_level]\n",
    "    sig_features = [param for param in sig_params if param in feature_cols and param != treatment_col]\n",
    "    sig_coeffs = { feature: round(est.params[feature], 4) for feature in sig_features }\n",
    "    sig_f_effects = [param for param in sig_params if param not in feature_cols]\n",
    "    \n",
    "    return {\n",
    "        'Label': label,\n",
    "        'Regression P': est.f_pvalue,\n",
    "        'Treatment significance': est.pvalues[treatment_col],\n",
    "        'Treatment coefficient': est.params[treatment_col],\n",
    "        'Sig feature coefficient': sig_coeffs,\n",
    "        'Sig feature p-values': { col: round(est.pvalues[col], 4) for col in sig_features },\n",
    "        'Number significant FE': len(sig_f_effects),\n",
    "        'Mean coefficient on FE': max([value for param, value in est.params.items() if param in sig_f_effects]),\n",
    "        'Keyword args': est_kwards\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_treatment_results('Replication', r_est, 'edu_ner', 'mean_pc_last_5', data_cols, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kwargs default: log_target=False, log_treatment=False, remove_feature_cols=[], # this last is convenience \n",
    "#                        add_country_feffects=True, add_constant=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_grid = {\n",
    "    'Straight replication': {\n",
    "        'target_col': 'edu_ner', \n",
    "        'treatment_col': 'mean_pc_last_5',\n",
    "        'est_kw_args': dict(\n",
    "            add_country_feffects=True, add_constant=False, log_target=True, log_treatment=True,\n",
    "            remove_feature_cols=['prior_ner_growth', 'w_avg_rating', 'satisfactory_proj', 'prior_4year_growth']\n",
    "        )\n",
    "    },\n",
    "    'Include weighted average rating': {\n",
    "        'target_col': 'edu_ner', \n",
    "        'treatment_col': 'mean_pc_last_5',\n",
    "        'est_kw_args': dict(\n",
    "            add_country_feffects=True, add_constant=False, log_target=True, log_treatment=True,\n",
    "            remove_feature_cols=['prior_ner_growth', 'satisfactory_proj', 'prior_4year_growth']\n",
    "        )\n",
    "    },\n",
    "    'Include constant term in regression': {\n",
    "        'target_col': 'edu_ner', \n",
    "        'treatment_col': 'mean_pc_last_5',\n",
    "        'est_kw_args': dict(\n",
    "            add_country_feffects=True, add_constant=True, log_target=True, log_treatment=True,\n",
    "            remove_feature_cols=['prior_ner_growth', 'w_avg_rating', 'satisfactory_proj', 'prior_4year_growth']\n",
    "        )        \n",
    "    },\n",
    "    'Include prior growth across education outcomes': {\n",
    "        'target_col': 'edu_ner', \n",
    "        'treatment_col': 'mean_pc_last_5',\n",
    "        'est_kw_args': dict(\n",
    "            add_country_feffects=True, add_constant=False, log_target=True, log_treatment=True,\n",
    "            remove_feature_cols=['prior_ner_growth', 'satisfactory_proj', 'w_avg_rating']\n",
    "        )\n",
    "    },\n",
    "    'Use growth in NER as target': {\n",
    "        'target_col': 'prior_ner_growth', \n",
    "        'treatment_col': 'mean_pc_last_5',\n",
    "        'est_kw_args': dict(\n",
    "            add_country_feffects=True, add_constant=True, log_target=True, log_treatment=True,\n",
    "            remove_feature_cols=['edu_ner', 'w_avg_rating', 'satisfactory_proj', 'prior_4year_growth']\n",
    "        )\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_search_result = []\n",
    "estimators = {}\n",
    "for label, args in search_grid.items():\n",
    "    est = evaluate_treatment(df, args['target_col'], args['treatment_col'], data_cols, **args['est_kw_args'])\n",
    "    results = extract_treatment_results(label, est, args['target_col'], args['treatment_col'], data_cols, args['est_kw_args'])\n",
    "    treatment_search_result.append(results)\n",
    "    estimators[label] = est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_results = pd.DataFrame(treatment_search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./growth_not_abs_ner_target.txt\", \"w\") as file:\n",
    "    file.write(estimators['Use growth in NER as target'].summary().as_text())\n",
    "    \n",
    "with open(\"./base_replication_full.txt\", \"w\") as file:\n",
    "    file.write(estimators['Straight replication'].summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_results.to_csv('../data/results/education_model_crawl.csv', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** (0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.edu_ner.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est.pvalues['mean_pc_last_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** (0.1101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if we leave in weighted average rating\n",
    "# data_cols += ['max_proj_rating_5']\n",
    "n_est = evaluate_treatment(df, 'edu_ner', 'mean_pc_last_5', data_cols,\n",
    "                          remove_feature_cols=['prior_ner_growth', 'w_avg_rating', 'satisfactory_proj', 'prior_4year_growth'],\n",
    "                          add_country_feffects=True, add_constant=False, log_target=True, log_treatment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.edu_ner.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean_pc_last_5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dml_est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(target_est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-tanzania",
   "metadata": {},
   "source": [
    "## Next round of simple replications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: restrict to projects with satisfactory ratings and better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = evaluate_treatment(df, 'edu_ner', 'satisfactory_proj', data_cols,\n",
    "                          remove_feature_cols=['prior_ner_growth', 'w_avg_rating', 'prior_4year_growth'],\n",
    "                          add_country_feffects=True, add_constant=False, log_target=True, log_treatment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second: construct exploratory function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third: conduct for health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth: repeat for WASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth: summarize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth: move onto EconML, and start planning the writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-grocery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future: do a pair-wise comparison, e.g., using BERT and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-folks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tracked-deadline",
   "metadata": {},
   "source": [
    "## Now use EconML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dml import LinearDML\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from econml.inference import BootstrapInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatment_col = 'project_completed_year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['pc_commit_education', 'edu_pupil_teacher', 'young_population', 'gdp_pc_ppp', \n",
    "                'cash_surplus_deficit', 'inflation', 'trade_share_gdp', 'freedom_house', 'prior_4year_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, T, X, W = experiment.assemble_econml_tuples(df, target_col, treatment_col, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = LinearDML(model_t=LogisticRegressionCV(max_iter=500), discrete_treatment=True)\n",
    "# est = LinearDML(model_t=RandomForestClassifier(), discrete_treatment=True)\n",
    "est.fit(Y, T, X=X, W=W) # W -> high-dimensional confounders, X -> features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est.score_)\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# point = est.const_marginddal_effect(X)\n",
    "# print(point)\n",
    "# est.effect(X, T0=False, T1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating some crawls, to find anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-gazette",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "causal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
